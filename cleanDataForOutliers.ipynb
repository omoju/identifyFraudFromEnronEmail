{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from time import time\n",
    "import matplotlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPath = '/Users/omojumiller/mycode/MachineLearningNanoDegree/IntroToMachineLearning/'\n",
    "sys.path.append(dataPath+'tools/')\n",
    "sys.path.append(dataPath+'final_project/')\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from helper_files import compareTwoFeatures, computeFraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "\n",
    "with open(dataPath+'final_project/final_project_dataset.pkl', \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are outliers, remove outliers\n",
    "\n",
    "This is an iteratable process. I need to do this for each combination of features I want to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = compareTwoFeatures('salary', 'bonus', data_dict, \"SALARY versus BONUS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I need to find out where that outlier is\n",
    "2. Find out who it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(data > 0.8 * 1e8) # This is where the outlier is, what I have to do now is find out who it is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[57] # So whose bonus is 97343619?\n",
    "# Whatâ€™s the name of the dictionary key of this data point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in data_dict.iteritems():\n",
    "    if (value['bonus'] >= int(data[57][1]) and \n",
    "        value['bonus'] != \"NaN\" and\n",
    "        value['salary'] != \"NaN\"):\n",
    "        print \"{:20}{:12}${:<12,.2f}{:12}${:<12,.2f}\".format(key, 'salary is ', value['salary'],\n",
    "                                                   ' bonus ', value['bonus'])\n",
    "        \n",
    "    if (value['restricted_stock'] < 0):\n",
    "        print key\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found the source of the outlier. It was the `TOTAL` row that was mistakenly read into the data dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the source of the outlier\n",
    "data_dict.pop( 'TOTAL')\n",
    "data_dict.pop( 'BHATNAGAR SANJAY')\n",
    "\n",
    "# We can now go back and rerun the regression to see what the data really looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = compareTwoFeatures('salary', 'bonus', data_dict, \"SALARY versus BONUS cleansed of outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_list = ['restricted_stock', 'exercised_stock_options'] #\n",
    "data = featureFormat( data_dict, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features, \n",
    "                                            target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "target_test = np.asarray(target_test).reshape(-1,1)\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "    \n",
    "# Reshape data using X.reshape(-1, 1) since data has a single feature or X.\n",
    "clf = reg.fit(feature_train, target_train)\n",
    "\n",
    "\n",
    "print \"slope of regression is %.2f\" % reg.coef_\n",
    "print \"intercepts of regression is %.2f\" % reg.intercept_\n",
    "print \"\\n ********stats on dataset********\\n\"\n",
    "print \"r-squared score on testing data: \", reg.score(feature_test, target_test)\n",
    "print \"r-squared score on training data: \", reg.score(feature_train, target_train)\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(feature_train, target_train, color=\"c\", label=\"train data\", s=80, marker = 'o', alpha = 0.28)\n",
    "plt.scatter(feature_test, target_test, color=\"r\", label=\"test data\", s=80, marker = 'o', alpha = 0.28)\n",
    "\n",
    "plt.plot(target_test, reg.predict(target_test), color=\"k\")\n",
    "plt.legend(loc='upper center', shadow=True, fontsize='medium')\n",
    "plt.ylabel(features_list[0])\n",
    "plt.xlabel(features_list[1])\n",
    "plt.title('Regression on the '+features_list[0]+' against the '+features_list[1], y=1.08)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = ['poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances', \n",
    "                'bonus', 'restricted_stock_deferred', 'deferred_income', \n",
    "                'total_stock_value', 'expenses', 'exercised_stock_options', 'other', \n",
    "                'long_term_incentive', \n",
    "                'restricted_stock', 'director_fees',\n",
    "                'to_messages','from_poi_to_this_person', 'from_messages', \n",
    "                'from_this_person_to_poi', 'shared_receipt_with_poi'\n",
    "               ]\n",
    "\n",
    "names = ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', \n",
    "        'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', \n",
    "        'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', \n",
    "         'director_fees','to_messages', 'from_poi_to_this_person', 'from_messages', \n",
    "                'from_this_person_to_poi', 'shared_receipt_with_poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_dataset = data_dict\n",
    "data = featureFormat(my_dataset, feature_list\n",
    "                     , sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omojumiller/anaconda/lib/python2.7/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=6.226e-04, previous alpha=9.166e-06, with an active set of 17 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(1.0, 'shared_receipt_with_poi'), (0.965, 'to_messages'), (0.95, 'deferral_payments'), (0.945, 'from_this_person_to_poi'), (0.89, 'from_messages'), (0.875, 'deferred_income'), (0.815, 'director_fees'), (0.76, 'loan_advances'), (0.735, 'from_poi_to_this_person'), (0.54, 'restricted_stock_deferred'), (0.535, 'exercised_stock_options'), (0.295, 'total_stock_value'), (0.285, 'other'), (0.205, 'expenses'), (0.145, 'salary'), (0.13, 'bonus'), (0.12, 'restricted_stock'), (0.115, 'long_term_incentive'), (0.04, 'total_payments')]\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "\n",
    "rlasso = RandomizedLasso()\n",
    "rlasso.fit(features, labels)\n",
    " \n",
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), \n",
    "                 names), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['poi', 'deferral_payments', 'deferred_income', \n",
    "                'restricted_stock_deferred', \n",
    "                'expenses','from_this_person_to_poi'\n",
    "               ]\n",
    "\n",
    "my_dataset = data_dict\n",
    "\n",
    "data = featureFormat(my_dataset, feature_list\n",
    "                     , sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Export data \n",
    "Dump  dataset to a .pkl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATASET_PICKLE_FILENAME = \"cleaned_dataset.pkl\"\n",
    "\n",
    "with open(DATASET_PICKLE_FILENAME, \"w\") as dataset_outfile:\n",
    "    pickle.dump(data_dict, dataset_outfile)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
