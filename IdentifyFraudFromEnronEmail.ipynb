{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Fraud from Enron Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from time import time\n",
    "import matplotlib as pl\n",
    "import pickle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataPath = '/Users/omojumiller/mycode/MachineLearningNanoDegree/IntroToMachineLearning/'\n",
    "sys.path.append(dataPath+'tools/')\n",
    "sys.path.append(dataPath+'final_project/')\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Procedure\n",
    "\n",
    "1. Transform data to the numeric format. May not need to do this if not using SVM\n",
    "2. Conduct simple scaling on the data\n",
    "3. Use **Random Forest Classifier** to do feature selection\n",
    "4. Feed those features into an **SVM**\n",
    "- Consider the RBF kernel K(x, y)\n",
    "- Use cross-validation to find the best parameter C and γ\n",
    "- Use the best parameter C and γ to train the whole training set\n",
    "- Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "- features_list is a list of strings, each of which is a feature name.\n",
    "- The first feature must be \"poi\".\n",
    "\n",
    "The dataset used in this project is store in a Python dictionary created by combining the Enron email and financial data, where each key-value pair in the dictionary corresponds to one person. The dictionary key is the person's name, and the value is another dictionary, which contains the names of all the features and their values for that person. The features in the data fall into three major types, namely financial features, email features and POI labels.\n",
    "\n",
    "financial features: ['salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees']\n",
    "\n",
    "email features: ['to_messages', 'email_address', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi']\n",
    "\n",
    "POI label: [‘poi’]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['poi','salary', 'exercised_stock_options', 'restricted_stock',\n",
    "                 'from_poi_to_this_person','from_this_person_to_poi'] # You will need to use more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "\n",
    "with open(dataPath+'final_project/final_project_dataset.pkl', \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Remove outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********Regression on salary to predict bonus ********\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAE3CAYAAACjCJZyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5ACEEKJC+f/0RBVyhjiA8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11080bf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope of regression is 3.63\n",
      "intercepts of regression is 347408.54\n",
      "\n",
      " ********stats on dataset********\n",
      "\n",
      "r-squared score on testing data:  0.304450238829\n",
      "r-squared score on training data:  0.989084305862\n"
     ]
    }
   ],
   "source": [
    "print \"\\n ********Regression on salary to predict bonus ********\\n\"\n",
    "\n",
    "features_list = [ 'bonus', 'salary']\n",
    "data = featureFormat(data_dict, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features,\n",
    "                                                                          target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"r\"\n",
    "\n",
    "\n",
    "\n",
    "### Regression \n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(feature_train, target_train)\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "plt.xticks(np.arange(0, 2e6, 100000), rotation = -60)\n",
    "plt.xlim((0, 2e6))\n",
    "plt.ylim((0, 1e7))\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print \"slope of regression is %.2f\" % reg.coef_\n",
    "print \"intercepts of regression is %.2f\" % reg.intercept_\n",
    "\n",
    "print \"\\n ********stats on dataset********\\n\"\n",
    "print \"r-squared score on testing data: \", reg.score(feature_test, target_test)\n",
    "print \"r-squared score on training data: \", reg.score(feature_train, target_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### len(zip(feature_train,  target_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Create new feature(s)\n",
    "- Store to `my_dataset` for easy export below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features and labels from dataset for local testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Try a variety of classifiers\n",
    "- Please name your classifier clf for easy export below.\n",
    "- Note that if you want to do PCA or other multi-stage operations, you'll need to use Pipelines. For more info: http://scikit-learn.org/stable/modules/pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Tune your classifier\n",
    "- Achieve better than .3 precision and recall. Using our testing script. Check the `tester.py` script in the final project folder for details on the evaluation method, especially the test_classifier function. Because of the small size of the dataset, the script uses `stratified shuffle split cross validation`. For more info: http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example starting point. Try investigating other evaluation techniques!\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: \n",
    "Dump your classifier, dataset, and features_list so anyone can check your results. You do not need to change anything below, but make sure that the version of `poi_id.py` that you submit can be run on its own and generates the necessary .pkl files for validating your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Starter code for the regression mini-project.\n",
    "    \n",
    "    Loads up/formats a modified version of the dataset\n",
    "    (why modified?  we've removed some trouble points\n",
    "    that you'll find yourself in the outliers mini-project).\n",
    "\n",
    "    Draws a little scatterplot of the training/testing data\n",
    "\n",
    "    You fill in the regression code where indicated:\n",
    "\"\"\"    \n",
    "\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "dictionary = pickle.load( open(dataPath+'/final_project/final_project_dataset_modified.pkl', \"r\") )\n",
    "\n",
    "### list the features you want to look at--first item in the \n",
    "### list will be the \"target\" feature\n",
    "\n",
    "print \"\\n ********Regression on salary to predict bonus ********\\n\"\n",
    "\n",
    "features_list = [\"bonus\", \"salary\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features, \n",
    "                                            target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"r\"\n",
    "\n",
    "\n",
    "\n",
    "### Your regression goes here!\n",
    "### Please name it reg, so that the plotting code below picks it up and \n",
    "### plots it correctly. Don't forget to change the test_color above from \"b\" to\n",
    "### \"r\" to differentiate training points from test points.\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(feature_train, target_train)\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print \"slope of regression is %.2f\" % reg.coef_\n",
    "print \"intercepts of regression is %.2f\" % reg.intercept_\n",
    "\n",
    "print \"\\n ********stats on dataset********\\n\"\n",
    "print \"r-squared score on testing data: \", reg.score(feature_test, target_test)\n",
    "print \"r-squared score on training data: \", reg.score(feature_train, target_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An r-squared score of -1.48499241737 is pretty bad. \n",
    "\n",
    "There are lots of finance features available, some of which might be more powerful than others in terms of predicting a person’s bonus. For example, suppose you thought about the data a bit and guess that the ```long_term_incentive``` feature, which is supposed to reward employees for contributing to the long-term health of the company, might be more closely related to a person’s bonus than their salary is.\n",
    "\n",
    "A way to confirm that you’re right in this hypothesis is to regress the bonus against the long term incentive, and see if the regression score is significantly higher than regressing the bonus against the salary. **Perform the regression of bonus against long term incentive--what’s the score on the test data?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"\\n ********Regression on long_term_incentive to predict bonus ********\\n\"\n",
    "\n",
    "\n",
    "features_list = [\"bonus\", \"long_term_incentive\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"r\"\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(feature_train, target_train)\n",
    "\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )\n",
    "except NameError:\n",
    "    pass\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print \"slope of regression is %.2f\" % reg.coef_\n",
    "print \"intercepts of regression is %.2f\" % reg.intercept_\n",
    "\n",
    "print \"\\n ********stats on dataset********\\n\"\n",
    "print \"r-squared score on testing data: \", reg.score(feature_test, target_test)\n",
    "print \"r-squared score on training data: \", reg.score(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Go back to a setup where you are using the salary to predict the bonus, and rerun the code to remind yourself of what the data look like.** You might notice a few data points that fall outside the main trend, someone who gets a high salary (over a million dollars!) but a relatively small bonus. This is an example of an outlier, and we’ll spend lots of time on them in the next lesson.\n",
    "\n",
    "A point like this can have a big effect on a regression: if it falls in the training set, it can have a significant effect on the slope/intercept if it falls in the test set, it can make the score much lower than it would otherwise be as things stand right now, this point falls into the test set (and probably hurting the score on our test data as a result). Let’s add a little hack to see what happens if it falls in the training set instead. Add these two lines near the bottom right before ```plt.xlabel(features_list[1]):```\n",
    "\n",
    "```python\n",
    "reg.fit(feature_test, target_test)\n",
    "plt.plot(feature_train, reg.predict(feature_train), color=\"b\")\n",
    "```\n",
    "\n",
    "Now we’ll be drawing two regression lines, one fit on the test data (with outlier) and one fit on the training data (no outlier). Look at the plot now--big difference, huh? That single outlier is driving most of the difference. **What’s the slope of the new regression line?**\n",
    "\n",
    "(That’s a big difference, and it’s mostly driven by the outliers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "dictionary = pickle.load( open(dataPath+'/final_project/final_project_dataset_modified.pkl', \"r\") )\n",
    "\n",
    "### list the features you want to look at--first item in the \n",
    "### list will be the \"target\" feature\n",
    "\n",
    "print \"\\n ********Regression on salary to predict bonus, cleaned for Outliers ********\\n\"\n",
    "\n",
    "features_list = [\"bonus\", \"salary\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"r\"\n",
    "\n",
    "\n",
    "\n",
    "### Your regression goes here!\n",
    "### Please name it reg, so that the plotting code below picks it up and \n",
    "### plots it correctly. Don't forget to change the test_color above from \"b\" to\n",
    "### \"r\" to differentiate training points from test points.\n",
    "\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(feature_train, target_train)\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "reg.fit(feature_test, target_test)\n",
    "plt.plot(feature_train, reg.predict(feature_train), color=\"b\") \n",
    "\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print \"slope of regression is %.2f\" % reg.coef_\n",
    "print \"intercepts of regression is %.2f\" % reg.intercept_\n",
    "\n",
    "print \"\\n ********stats on dataset********\\n\"\n",
    "print \"r-squared score on testing data: \", reg.score(feature_test, target_test)\n",
    "print \"r-squared score on training data: \", reg.score(feature_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
